{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import tensorflow.keras as keras\n",
    "import datetime\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import *\n",
    "from src.score import *\n",
    "from src.data_generator import *\n",
    "from src.networks import *\n",
    "from src.train import *\n",
    "from src.clr import LRFinder, OneCycleLR\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(5)\n",
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longer skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_long_skip(filters, kernels, input_shape, bn_position=None, use_bias=True, l2=0,\n",
    "                 skip=True, dropout=0, activation='relu', **kwargs):\n",
    "    x = input = Input(shape=input_shape)\n",
    "\n",
    "    # First conv block to get up to shape\n",
    "    x = ls = convblock(\n",
    "        x, filters[0], kernels[0], bn_position=bn_position, l2=l2, use_bias=use_bias,\n",
    "        dropout=dropout, activation=activation\n",
    "    )\n",
    "\n",
    "    # Resblocks\n",
    "    for f, k in zip(filters[1:-1], kernels[1:-1]):\n",
    "        x = resblock(x, f, k, bn_position=bn_position, l2=l2, use_bias=use_bias,\n",
    "                dropout=dropout, skip=skip, activation=activation)\n",
    "        x = Add()([x, ls])\n",
    "\n",
    "    # Final convolution\n",
    "    output = PeriodicConv2D(\n",
    "        filters[-1], kernels[-1],\n",
    "        conv_kwargs={'kernel_regularizer': regularizers.l2(l2)},\n",
    "    )(x)\n",
    "    output = Activation('linear', dtype='float32')(output)\n",
    "    return keras.models.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet_long_skip([128, 128, 35], [7, 3, 3], (32, 64, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 64, 35)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_3 (PeriodicConv (None, 32, 64, 128)  219648      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 64, 128)  0           periodic_conv2d_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_4 (PeriodicConv (None, 32, 64, 128)  147584      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 64, 128)  0           periodic_conv2d_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_5 (PeriodicConv (None, 32, 64, 128)  147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 64, 128)  0           periodic_conv2d_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 64, 128)  0           activation_3[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 64, 128)  0           add_1[0][0]                      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_6 (PeriodicConv (None, 32, 64, 35)   40355       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 64, 35)   0           periodic_conv2d_6[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 555,171\n",
      "Trainable params: 555,171\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Small no multi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = load_args('../nn_configs/B/92-resnet_multi_dt.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdir = args['datadir']\n",
    "z500_valid = load_test_data(f'{valdir}geopotential_500', 'z').drop('level')\n",
    "t850_valid = load_test_data(f'{valdir}temperature_850', 't').drop('level')\n",
    "valid = xr.merge([z500_valid, t850_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['exp_id'] = '92.1-resnet_multi_dt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['train_years'] = ['2015', '2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['ext_mean'] = xr.open_dataarray(f\"{args['model_save_dir']}/{args['exp_id']}_mean.nc\")\n",
    "args['ext_std'] = xr.open_dataarray(f\"{args['model_save_dir']}/{args['exp_id']}_std.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['multi_dt'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_train, dg_valid, dg_test = load_data(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 4374)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dg_train), dg_train.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['filters'] = [128, 128, 128, 128, 128, 35]\n",
    "args['kernels'] = [7, 3, 3, 3, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet(input_shape = dg_train.shape, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_multi_dt_model(model, args['multi_dt'], dg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 32, 64, 38)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_124 (PeriodicCo (None, 32, 64, 128)  238464      input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_119 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_124[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_125 (PeriodicCo (None, 32, 64, 128)  147584      dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_120 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_125[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_126 (PeriodicCo (None, 32, 64, 128)  147584      dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_121 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_126[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 32, 64, 128)  0           dropout_119[0][0]                \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_127 (PeriodicCo (None, 32, 64, 128)  147584      add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_122 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_127[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_128 (PeriodicCo (None, 32, 64, 128)  147584      dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_123 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_128[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 32, 64, 128)  0           add_57[0][0]                     \n",
      "                                                                 dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_129 (PeriodicCo (None, 32, 64, 128)  147584      add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_124 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_129[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_130 (PeriodicCo (None, 32, 64, 128)  147584      dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_125 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_130[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 32, 64, 128)  0           add_58[0][0]                     \n",
      "                                                                 dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_131 (PeriodicCo (None, 32, 64, 128)  147584      add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_126 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_131[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_132 (PeriodicCo (None, 32, 64, 128)  147584      dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_127 (LeakyReLU)     (None, 32, 64, 128)  0           periodic_conv2d_132[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 32, 64, 128)  512         leaky_re_lu_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 32, 64, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 32, 64, 128)  0           add_59[0][0]                     \n",
      "                                                                 dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "periodic_conv2d_133 (PeriodicCo (None, 32, 64, 35)   40355       add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 64, 35)   0           periodic_conv2d_133[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,464,099\n",
      "Trainable params: 1,461,795\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = create_lat_mse(dg_train.data.lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-05"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 137 steps, validate for 10 steps\n",
      "Epoch 1/100\n",
      "137/137 [==============================] - 11s 77ms/step - loss: 1.9125\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.6488\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.4822\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.3975\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 8s 58ms/step - loss: 0.3444 - val_loss: 0.1912\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.3071\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.2792\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.2573\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.2393\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.2245 - val_loss: 0.1587\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.2118\n",
      "Epoch 12/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.2008\n",
      "Epoch 13/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.1913\n",
      "Epoch 14/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.1829\n",
      "Epoch 15/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.1757 - val_loss: 0.1421\n",
      "Epoch 16/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.1690\n",
      "Epoch 17/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1632\n",
      "Epoch 18/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.1580\n",
      "Epoch 19/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.1532\n",
      "Epoch 20/100\n",
      "137/137 [==============================] - 7s 55ms/step - loss: 0.1490 - val_loss: 0.1323\n",
      "Epoch 21/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.1451\n",
      "Epoch 22/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1414\n",
      "Epoch 23/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1382\n",
      "Epoch 24/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1352\n",
      "Epoch 25/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.1324 - val_loss: 0.1237\n",
      "Epoch 26/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.1298\n",
      "Epoch 27/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.1274\n",
      "Epoch 28/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.1252\n",
      "Epoch 29/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.1232\n",
      "Epoch 30/100\n",
      "137/137 [==============================] - 7s 55ms/step - loss: 0.1212 - val_loss: 0.1167\n",
      "Epoch 31/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.1195\n",
      "Epoch 32/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1178\n",
      "Epoch 33/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1161\n",
      "Epoch 34/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1148\n",
      "Epoch 35/100\n",
      "137/137 [==============================] - 7s 55ms/step - loss: 0.1133 - val_loss: 0.1107\n",
      "Epoch 36/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.1120\n",
      "Epoch 37/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1109\n",
      "Epoch 38/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.1097\n",
      "Epoch 39/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.1086\n",
      "Epoch 40/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.1076 - val_loss: 0.1060\n",
      "Epoch 41/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.1066\n",
      "Epoch 42/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.1057\n",
      "Epoch 43/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.1048\n",
      "Epoch 44/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.1040\n",
      "Epoch 45/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.1031 - val_loss: 0.1025\n",
      "Epoch 46/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.1024\n",
      "Epoch 47/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.1016\n",
      "Epoch 48/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.1008\n",
      "Epoch 49/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.1001\n",
      "Epoch 50/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.0995 - val_loss: 0.0992\n",
      "Epoch 51/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0988\n",
      "Epoch 52/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0981\n",
      "Epoch 53/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0976\n",
      "Epoch 54/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0970\n",
      "Epoch 55/100\n",
      "137/137 [==============================] - 8s 55ms/step - loss: 0.0963 - val_loss: 0.0964\n",
      "Epoch 56/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.0958\n",
      "Epoch 57/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0952\n",
      "Epoch 58/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0947\n",
      "Epoch 59/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0941\n",
      "Epoch 60/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.0936 - val_loss: 0.0939\n",
      "Epoch 61/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0931\n",
      "Epoch 62/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0926\n",
      "Epoch 63/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0923\n",
      "Epoch 64/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0917\n",
      "Epoch 65/100\n",
      "137/137 [==============================] - 8s 55ms/step - loss: 0.0912 - val_loss: 0.0915\n",
      "Epoch 66/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0909\n",
      "Epoch 67/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0904\n",
      "Epoch 68/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0900\n",
      "Epoch 69/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.0897\n",
      "Epoch 70/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.0892 - val_loss: 0.0901\n",
      "Epoch 71/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.0888\n",
      "Epoch 72/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0885\n",
      "Epoch 73/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.0881\n",
      "Epoch 74/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0877\n",
      "Epoch 75/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.0874 - val_loss: 0.0883\n",
      "Epoch 76/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0871\n",
      "Epoch 77/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.0867\n",
      "Epoch 78/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0864\n",
      "Epoch 79/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.0861\n",
      "Epoch 80/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.0858 - val_loss: 0.0868\n",
      "Epoch 81/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0855\n",
      "Epoch 82/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0852\n",
      "Epoch 83/100\n",
      "137/137 [==============================] - 7s 53ms/step - loss: 0.0849: 0s \n",
      "Epoch 84/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0846\n",
      "Epoch 85/100\n",
      "137/137 [==============================] - 7s 55ms/step - loss: 0.0843 - val_loss: 0.0854\n",
      "Epoch 86/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0841\n",
      "Epoch 87/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0839\n",
      "Epoch 88/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0837\n",
      "Epoch 89/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0834\n",
      "Epoch 90/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.0833 - val_loss: 0.0836\n",
      "Epoch 91/100\n",
      "137/137 [==============================] - 7s 52ms/step - loss: 0.0829\n",
      "Epoch 92/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0827\n",
      "Epoch 93/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0825\n",
      "Epoch 94/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0822\n",
      "Epoch 95/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.0821 - val_loss: 0.0831\n",
      "Epoch 96/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0818\n",
      "Epoch 97/100\n",
      "137/137 [==============================] - 7s 50ms/step - loss: 0.0816\n",
      "Epoch 98/100\n",
      "137/137 [==============================] - 7s 51ms/step - loss: 0.0815\n",
      "Epoch 99/100\n",
      "137/137 [==============================] - 7s 49ms/step - loss: 0.0813\n",
      "Epoch 100/100\n",
      "137/137 [==============================] - 7s 54ms/step - loss: 0.0812 - val_loss: 0.0816\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(dg_train, epochs=100, validation_data=dg_valid, validation_freq=5, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = create_predictions(model, dg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<title>Show/Hide data repr</title>\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<title>Show/Hide attributes</title>\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt, dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><div class='xr-wrap'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'z_rmse'</div></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-96c639d5-349a-47ae-86d9-cba4ae56adf3' class='xr-array-in' type='checkbox' ><label for='section-96c639d5-349a-47ae-86d9-cba4ae56adf3' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>149.4</span></div><pre class='xr-array-data'>array(149.35683461)</pre></div></li><li class='xr-section-item'><input id='section-77944187-e218-4c7d-8d43-ea3b8554b97d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-77944187-e218-4c7d-8d43-ea3b8554b97d' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>level</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>500</div><input id='attrs-62aab28f-0644-4333-8282-083af8b94f30' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-62aab28f-0644-4333-8282-083af8b94f30' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ad20eec0-470b-4b03-ba90-1408c8769fe0' class='xr-var-data-in' type='checkbox'><label for='data-ad20eec0-470b-4b03-ba90-1408c8769fe0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><pre class='xr-var-data'>array(500)</pre></li></ul></div></li><li class='xr-section-item'><input id='section-56d363fe-6ec3-4b1d-83ab-9a3a59304da8' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-56d363fe-6ec3-4b1d-83ab-9a3a59304da8' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'z_rmse' ()>\n",
       "array(149.35683461)\n",
       "Coordinates:\n",
       "    level    int64 500"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_weighted_rmse(preds.z.sel(level=500), valid.z).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004705264355098457, 0.03995124958455563)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.history['loss'][-1], h.history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24*1000/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.plot(np.arange(5, 1001, 5), h.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train_hist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.464015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.401408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.448597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.031649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.801389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch      loss\n",
       "0      0  9.464015\n",
       "1      1  2.401408\n",
       "2      2  1.448597\n",
       "3      3  1.031649\n",
       "4      4  0.801389"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
